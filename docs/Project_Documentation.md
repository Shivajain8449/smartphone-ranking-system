ðŸ“± Smartphone Feature Ranking System
Machine Learning Project Documentation

ðŸŽ¯ PROJECT OVERVIEW
Project Title: Smartphone Feature Ranking and Classification System
Objective: To develop an intelligent system that classifies smartphones into categories and ranks them based on multiple features using Machine Learning and Multi-Criteria Decision Making (MCDM) techniques.
Algorithms Used:

Random Forest Classifier (for classification)
TOPSIS (Technique for Order of Preference by Similarity to Ideal Solution) for ranking


ðŸ“Š STAGE 1: DATA LOADING
What is Data Loading?
Data loading is the process of importing data from various sources into your program for analysis.
In This Project:

Data Source: CSV file or built-in sample dataset
Features Collected:

Battery capacity (mAh)
Camera resolution (MP)
Storage capacity (GB)
Processor speed (GHz)
RAM (GB)
Price (â‚¹)



Code Explanation:
pythondef load_data(self, data_source=None):
    if data_source:
        self.data = pd.read_csv(data_source)
    else:
        # Use sample data
Key Points to Explain:

âœ… We use Pandas library to load CSV files
âœ… Data is stored in a DataFrame (table structure)
âœ… Initial data inspection shows 10 smartphones with 6 features

Output:

Total records loaded
Feature names
Sample data preview


ðŸ§¹ STAGE 2: DATA PREPROCESSING
What is Preprocessing?
Cleaning and transforming raw data into a format suitable for machine learning models.
Steps Performed:
2.1 Missing Value Handling
python# Check for missing values
missing = self.data.isnull().sum()
# Fill with median
self.data = self.data.fillna(self.data.median())
Why? Missing data can cause errors in model training.
2.2 Duplicate Removal
pythonduplicates = self.data.duplicated().sum()
self.data = self.data.drop_duplicates()
Why? Duplicates can bias the model.
2.3 Feature Engineering

Category Creation: Classify phones into Budget/Mid-Range/Premium/Flagship based on price
Value Score: Calculate overall value combining all features

pythonself.data['CATEGORY'] = pd.cut(
    self.data['PRICE'], 
    bins=[0, 20000, 35000, 60000, inf],
    labels=['Budget', 'Mid-Range', 'Premium', 'Flagship']
)
2.4 Statistical Analysis

Calculate mean, median, standard deviation
Identify outliers
Understand data distribution

Key Points to Explain:

âœ… Clean data = Better model performance
âœ… Feature engineering creates new meaningful variables
âœ… Normalization brings all features to same scale


ðŸŽ“ STAGE 3: MODEL TRAINING
What is Training?
Teaching the machine learning model to recognize patterns in data.
Steps Performed:
3.1 Data Splitting
pythonX_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

70% Training Data: Used to teach the model
30% Testing Data: Used to evaluate performance

Why split? To test model on unseen data and avoid overfitting.
3.2 Feature Scaling
pythonscaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
Formula: z = (x - Î¼) / Ïƒ
Why? Features have different units (mAh vs GB vs â‚¹). Scaling makes them comparable.
3.3 Random Forest Training
pythonmodel = RandomForestClassifier(
    n_estimators=100,  # 100 decision trees
    max_depth=10,
    random_state=42
)
model.fit(X_train_scaled, y_train)
How Random Forest Works:

Creates multiple decision trees
Each tree votes on classification
Majority vote wins

Advantages:

âœ… Handles non-linear relationships
âœ… Resistant to overfitting
âœ… Provides feature importance

3.4 Feature Importance Analysis
Shows which features matter most:

Camera: 25%
Processor: 25%
Battery: 20%
RAM: 15%
Storage: 15%

3.5 TOPSIS Score Calculation
TOPSIS Algorithm Steps:
Step 1: Normalize the decision matrix
normalized = feature / sqrt(sum(featureÂ²))
Step 2: Apply weights to normalized values
weighted = normalized Ã— weight
Step 3: Identify ideal best and worst
Ideal Best = max(weighted values)
Ideal Worst = min(weighted values)
Step 4: Calculate Euclidean distances
Distance to Best = sqrt(Î£(value - ideal_best)Â²)
Distance to Worst = sqrt(Î£(value - ideal_worst)Â²)
Step 5: Calculate TOPSIS Score
Score = Distance to Worst / (Distance to Best + Distance to Worst)
Range: 0 to 1 (higher is better)
Key Points to Explain:

âœ… Training teaches the model patterns
âœ… Feature scaling is crucial for fair comparison
âœ… Random Forest uses ensemble learning
âœ… TOPSIS provides objective ranking


âœ… STAGE 4: TESTING & EVALUATION
What is Testing?
Evaluating how well the trained model performs on new, unseen data.
Metrics Used:
4.1 Accuracy
Accuracy = Correct Predictions / Total Predictions Ã— 100%
Example: If model correctly classifies 9 out of 10 phones = 90% accuracy
4.2 Confusion Matrix
                Predicted
              B   M   P   F
Actual   B   [2  0  0  0]
         M   [0  3  1  0]
         P   [0  0  2  0]
         F   [0  0  0  2]

Diagonal = Correct predictions
Off-diagonal = Errors

4.3 Precision, Recall, F1-Score
Precision: Of all phones predicted as "Premium", how many are actually Premium?
Precision = True Positives / (True Positives + False Positives)
Recall: Of all actual Premium phones, how many did we correctly identify?
Recall = True Positives / (True Positives + False Negatives)
F1-Score: Harmonic mean of Precision and Recall
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
4.4 Visualizations Created

Confusion Matrix Heatmap - Shows classification accuracy
Feature Importance Chart - Which features matter most
TOPSIS Distribution - Score spread across phones
Top 5 Rankings - Best performing smartphones

Key Points to Explain:

âœ… Testing on separate data prevents overfitting
âœ… Multiple metrics give complete picture
âœ… Confusion matrix shows where model makes mistakes
âœ… Visual charts make results easy to understand


ðŸš€ STAGE 5: DEPLOYMENT
What is Deployment?
Making the trained model available for real-world use.
Deployment Steps:
5.1 Model Serialization
pythonwith open('smartphone_classifier_model.pkl', 'wb') as f:
    pickle.dump(model, f)
Why? Save trained model to disk so we don't retrain every time.
5.2 Scaler Saving
pythonwith open('feature_scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
Why? New data must be scaled the same way.
5.3 Results Export

CSV file with complete rankings
Easy to share with others
Can be opened in Excel

5.4 Prediction Interface
pythondef predict_new_smartphone(features_dict):
    X_new_scaled = scaler.transform(X_new)
    category = model.predict(X_new_scaled)
    return category
Real-world Application:

User inputs new phone specs
System predicts category
Provides ranking score
Helps in purchase decision

Key Points to Explain:

âœ… Deployed model can be used in apps/websites
âœ… No need to retrain for new predictions
âœ… Results saved for future reference
âœ… System ready for production use


ðŸ“ˆ PROJECT RESULTS
Model Performance:

Accuracy: ~90% (depends on data)
Training Time: < 1 second
Prediction Time: < 0.01 seconds per phone

Top Ranked Smartphone:

Based on balanced feature scores
Considers price-to-performance ratio
Objective ranking (no bias)

Generated Outputs:

âœ… smartphone_classifier_model.pkl - Trained model
âœ… feature_scaler.pkl - Data scaler
âœ… final_smartphone_rankings.csv - Complete rankings
âœ… model_evaluation.png - Performance visualizations


ðŸ› ï¸ TECHNOLOGIES USED
TechnologyPurposePython 3.xProgramming languagePandasData manipulationNumPyNumerical computationsScikit-learnMachine learning algorithmsMatplotlibData visualizationSeabornStatistical visualizationPickleModel serialization

ðŸ’¡ KEY LEARNINGS
Technical Skills:

âœ… Data preprocessing techniques
âœ… Machine learning classification
âœ… Multi-criteria decision making (MCDM)
âœ… Model evaluation metrics
âœ… Model deployment strategies

Domain Knowledge:

âœ… Smartphone feature analysis
âœ… Consumer decision-making factors
âœ… Price-performance relationships


ðŸ”® FUTURE ENHANCEMENTS

More Features:

Screen size and resolution
5G connectivity
Water resistance rating
Brand reputation score
User reviews and ratings
Refresh rate (60Hz, 90Hz, 120Hz)
Fast charging capability


Advanced ML Algorithms:

Deep Learning (Neural Networks)
Gradient Boosting (XGBoost, LightGBM)
Support Vector Machines (SVM)
Ensemble methods combining multiple algorithms


Web Application:

User-friendly interface
Upload custom dataset
Interactive sliders for feature weights
Real-time predictions
Comparison tool for multiple phones


Mobile App:

Android/iOS application
Barcode scanner for instant specs
Personalized recommendations
Price alerts and notifications


Database Integration:

Store historical data
Track price trends
User preferences storage
Recommendation history


API Development:

RESTful API for third-party integration
E-commerce platform integration
Real-time data updates